# ğŸš€ Real-Time Spark Streaming Dashboard

![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=for-the-badge&logo=apachekafka&logoColor=white)
![Grafana](https://img.shields.io/badge/Grafana-F46800?style=for-the-badge&logo=grafana&logoColor=white)

## ğŸ“‹ Project Overview

A production-grade real-time data streaming and analytics dashboard that processes IoT sensor data using Apache Spark Streaming and visualizes insights through interactive dashboards. This project demonstrates end-to-end streaming data pipeline architecture with real-time processing capabilities.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  IoT Sensors    â”‚â”€â”€â”€â”€â–¶â”‚  Apache Kafka    â”‚â”€â”€â”€â”€â–¶â”‚  Spark Streamingâ”‚
â”‚  (Data Source)  â”‚     â”‚  (Message Queue) â”‚     â”‚  (Processing)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Grafana/       â”‚â—€â”€â”€â”€â”€â”‚  Time-Series DB  â”‚â—€â”€â”€â”€â”€â”‚  Data Transform â”‚
â”‚  Power BI       â”‚     â”‚  (InfluxDB)      â”‚     â”‚  & Aggregation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Key Features

- **Real-time Data Ingestion**: Continuous streaming from IoT sensors
- **Stream Processing**: Apache Spark Streaming for data transformation
- **Windowing Operations**: Time-based aggregations and analytics
- **Live Visualization**: Interactive dashboards with Grafana and Power BI
- **Scalable Architecture**: Horizontally scalable microservices design
- **Fault Tolerance**: Kafka for reliable message delivery
- **Monitoring & Alerts**: Real-time anomaly detection

## ğŸ› ï¸ Technologies Used

### Data Processing
- **Apache Spark 3.4+**: Distributed stream processing
- **PySpark**: Python API for Spark
- **Apache Kafka**: Distributed messaging system
- **Kafka Streams**: Stream processing library

### Data Storage
- **InfluxDB**: Time-series database
- **Redis**: In-memory caching
- **PostgreSQL**: Metadata storage

### Visualization
- **Grafana**: Real-time dashboard
- **Power BI**: Business intelligence reporting
- **Plotly**: Interactive visualizations

### DevOps & Tools
- **Docker**: Containerization
- **Docker Compose**: Multi-container orchestration
- **Python 3.9+**: Primary programming language
- **Git**: Version control

## ğŸ“ Project Structure

```
realtime-spark-streaming-dashboard/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_generator/
â”‚   â”‚   â”œâ”€â”€ iot_sensor_simulator.py
â”‚   â”‚   â””â”€â”€ config.yaml
â”‚   â”œâ”€â”€ streaming/
â”‚   â”‚   â”œâ”€â”€ spark_consumer.py
â”‚   â”‚   â”œâ”€â”€ transformations.py
â”‚   â”‚   â””â”€â”€ windowing.py
â”‚   â”œâ”€â”€ kafka/
â”‚   â”‚   â”œâ”€â”€ producer.py
â”‚   â”‚   â””â”€â”€ topics.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ helpers.py
â”‚
â”œâ”€â”€ dashboards/
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”œâ”€â”€ dashboard.json
â”‚   â”‚   â””â”€â”€ datasources.yaml
â”‚   â””â”€â”€ powerbi/
â”‚       â””â”€â”€ template.pbix
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ spark-defaults.conf
â”‚   â”œâ”€â”€ kafka-config.properties
â”‚   â””â”€â”€ influxdb.conf
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_streaming.py
â”‚   â””â”€â”€ test_transformations.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ data_exploration.ipynb
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ setup_guide.md
â”‚   â””â”€â”€ api_reference.md
â”‚
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ dashboard_overview.png
â”‚   â””â”€â”€ architecture_diagram.png
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ LICENSE
```

## ğŸš€ Setup Instructions

### Prerequisites
- Python 3.9 or higher
- Apache Spark 3.4+
- Docker & Docker Compose
- Apache Kafka 3.0+
- 8GB RAM minimum

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/Saideva0318/realtime-spark-streaming-dashboard.git
cd realtime-spark-streaming-dashboard
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Start services with Docker Compose**
```bash
cd docker
docker-compose up -d
```

5. **Configure environment variables**
```bash
cp .env.example .env
# Edit .env with your configurations
```

6. **Initialize Kafka topics**
```bash
python src/kafka/topics.py --create
```

7. **Start the data generator**
```bash
python src/data_generator/iot_sensor_simulator.py
```

8. **Launch Spark Streaming job**
```bash
spark-submit --master local[*] \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0 \
  src/streaming/spark_consumer.py
```

9. **Access Grafana Dashboard**
```
URL: http://localhost:3000
Username: admin
Password: admin
```

## ğŸ“Š Sample Output

### Real-Time Metrics Dashboard
![Dashboard Overview](screenshots/dashboard_overview.png)

### Key Metrics Tracked
- **Sensor Readings**: Temperature, humidity, pressure
- **Throughput**: Messages per second
- **Latency**: End-to-end processing time
- **Anomalies**: Real-time alert detection
- **System Health**: Resource utilization

## ğŸ”§ Configuration

### Spark Streaming Configuration
```python
# spark-defaults.conf
spark.streaming.stopGracefullyOnShutdown=true
spark.streaming.backpressure.enabled=true
spark.streaming.kafka.maxRatePerPartition=1000
spark.sql.streaming.metricsEnabled=true
```

### Kafka Producer Settings
```python
# kafka-config.properties
bootstrap.servers=localhost:9092
acks=all
retries=3
batch.size=16384
compression.type=snappy
```

## ğŸ“ˆ Performance Optimization

- **Batch Interval**: 5 seconds for optimal throughput
- **Parallelism**: 8 executors with 2 cores each
- **Memory**: 4GB per executor
- **Checkpointing**: Every 30 seconds
- **State Management**: RocksDB for state store

## ğŸ§ª Testing

Run unit tests:
```bash
pytest tests/ -v --cov=src
```

Run integration tests:
```bash
python -m pytest tests/integration/ -v
```

## ğŸ“ Future Enhancements

- [ ] Add machine learning models for predictive analytics
- [ ] Implement automatic scaling based on load
- [ ] Integration with AWS Kinesis
- [ ] Add support for multiple data sources
- [ ] Implement data quality checks
- [ ] Add authentication and authorization
- [ ] Create REST API for dashboard queries
- [ ] Add support for custom alerting rules
- [ ] Implement data lineage tracking
- [ ] Add A/B testing framework

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**Sai Deva Puttur**
- GitHub: [@Saideva0318](https://github.com/Saideva0318)
- LinkedIn: [Sai Deva Puttur](https://linkedin.com/in/sai-deva-puttur)

## ğŸ™ Acknowledgments

- Apache Spark community for excellent documentation
- Confluent for Kafka best practices
- Grafana Labs for visualization tools
- Real-time analytics community for inspiration

## ğŸ“ Contact

For questions or feedback, please open an issue or reach out via LinkedIn.

---

â­ **If you find this project useful, please consider giving it a star!** â­
